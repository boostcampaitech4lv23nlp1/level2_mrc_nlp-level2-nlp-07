{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|██████████| 4.76k/4.76k [00:00<00:00, 3.05MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.39k/2.39k [00:00<00:00, 1.66MB/s]\n",
      "Downloading readme: 100%|██████████| 6.13k/6.13k [00:00<00:00, 4.41MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad_kor_v1/squad_kor_v1 to /opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/18d4f44736b8ee85671f63cb84965bfb583fa0a4ff2df3c2e10eee9693796725...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/7.57M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 8.11MB [00:00, 81.1MB/s]                   \u001b[A\n",
      "Downloading data: 16.8MB [00:00, 84.2MB/s]\u001b[A\n",
      "Downloading data: 25.2MB [00:00, 84.4MB/s]\u001b[A\n",
      "Downloading data: 38.5MB [00:00, 84.1MB/s]\u001b[A\n",
      "Downloading data files:  50%|█████     | 1/2 [00:00<00:00,  1.27it/s]\n",
      "Downloading data: 3.88MB [00:00, 81.0MB/s]                  \u001b[A\n",
      "Downloading data files: 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "Extracting data files #0: 100%|██████████| 1/1 [00:00<00:00, 579.72obj/s]\n",
      "\n",
      "Extracting data files #1: 100%|██████████| 1/1 [00:00<00:00, 616.54obj/s]\n",
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_kor_v1 downloaded and prepared to /opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/18d4f44736b8ee85671f63cb84965bfb583fa0a4ff2df3c2e10eee9693796725. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 411.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "dataset = load_dataset(\"squad_kor_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 60407\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 5774\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets,Dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['context'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tmp = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6566495-0-0</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?</td>\n",
       "      <td>{'text': ['교향곡'], 'answer_start': [54]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6566495-0-1</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?</td>\n",
       "      <td>{'text': ['1악장'], 'answer_start': [421]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6566495-0-2</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?</td>\n",
       "      <td>{'text': ['베토벤의 교향곡 9번'], 'answer_start': [194]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6566518-0-0</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?</td>\n",
       "      <td>{'text': ['파우스트'], 'answer_start': [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6566518-0-1</td>\n",
       "      <td>파우스트_서곡</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?</td>\n",
       "      <td>{'text': ['합창교향곡'], 'answer_start': [354]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60402</th>\n",
       "      <td>6467478-1-1</td>\n",
       "      <td>뉴델리_메탈로-베타락타마제</td>\n",
       "      <td>유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (...</td>\n",
       "      <td>뉴델리 메탈로 베타락마제가 처음 감염 된 지역은 어디인가?</td>\n",
       "      <td>{'text': ['인도'], 'answer_start': [73]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60403</th>\n",
       "      <td>6467478-2-0</td>\n",
       "      <td>뉴델리_메탈로-베타락타마제</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>균은 유전자를 균에게 전달 할 수있는데 이러한 현상을 나타낸 용어는 무엇인가?</td>\n",
       "      <td>{'text': ['유전자 전달'], 'answer_start': [253]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60404</th>\n",
       "      <td>6467478-2-1</td>\n",
       "      <td>뉴델리_메탈로-베타락타마제</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>박테리아가 NDM-1 유전자를 가지고 있을때 발생하는 전파를 분석하기위해 사용된 영...</td>\n",
       "      <td>{'text': ['37건'], 'answer_start': [129]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60405</th>\n",
       "      <td>6490801-2-0</td>\n",
       "      <td>뉴델리_메탈로-베타락타마제</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>NDM-1 유전자를 가진 박테리아가 감수성을 보인 폴리믹슨 계열 항생제는?</td>\n",
       "      <td>{'text': ['콜리스틴'], 'answer_start': [404]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60406</th>\n",
       "      <td>6490801-2-1</td>\n",
       "      <td>뉴델리_메탈로-베타락타마제</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>2010년 8월, NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석한 다국적 ...</td>\n",
       "      <td>{'text': ['The Lancet Infectious Diseases'], '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60407 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id           title  \\\n",
       "0      6566495-0-0         파우스트_서곡   \n",
       "1      6566495-0-1         파우스트_서곡   \n",
       "2      6566495-0-2         파우스트_서곡   \n",
       "3      6566518-0-0         파우스트_서곡   \n",
       "4      6566518-0-1         파우스트_서곡   \n",
       "...            ...             ...   \n",
       "60402  6467478-1-1  뉴델리_메탈로-베타락타마제   \n",
       "60403  6467478-2-0  뉴델리_메탈로-베타락타마제   \n",
       "60404  6467478-2-1  뉴델리_메탈로-베타락타마제   \n",
       "60405  6490801-2-0  뉴델리_메탈로-베타락타마제   \n",
       "60406  6490801-2-1  뉴델리_메탈로-베타락타마제   \n",
       "\n",
       "                                                 context  \\\n",
       "0      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "1      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "2      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "3      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "4      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "...                                                  ...   \n",
       "60402  유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (...   \n",
       "60403  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60404  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60405  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60406  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "\n",
       "                                                question  \\\n",
       "0                         바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?   \n",
       "1                          바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?   \n",
       "2                      바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?   \n",
       "3                         1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?   \n",
       "4                       파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?   \n",
       "...                                                  ...   \n",
       "60402                   뉴델리 메탈로 베타락마제가 처음 감염 된 지역은 어디인가?   \n",
       "60403        균은 유전자를 균에게 전달 할 수있는데 이러한 현상을 나타낸 용어는 무엇인가?   \n",
       "60404  박테리아가 NDM-1 유전자를 가지고 있을때 발생하는 전파를 분석하기위해 사용된 영...   \n",
       "60405          NDM-1 유전자를 가진 박테리아가 감수성을 보인 폴리믹슨 계열 항생제는?   \n",
       "60406  2010년 8월, NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석한 다국적 ...   \n",
       "\n",
       "                                                 answers  \n",
       "0                {'text': ['교향곡'], 'answer_start': [54]}  \n",
       "1               {'text': ['1악장'], 'answer_start': [421]}  \n",
       "2       {'text': ['베토벤의 교향곡 9번'], 'answer_start': [194]}  \n",
       "3               {'text': ['파우스트'], 'answer_start': [15]}  \n",
       "4             {'text': ['합창교향곡'], 'answer_start': [354]}  \n",
       "...                                                  ...  \n",
       "60402             {'text': ['인도'], 'answer_start': [73]}  \n",
       "60403        {'text': ['유전자 전달'], 'answer_start': [253]}  \n",
       "60404           {'text': ['37건'], 'answer_start': [129]}  \n",
       "60405          {'text': ['콜리스틴'], 'answer_start': [404]}  \n",
       "60406  {'text': ['The Lancet Infectious Diseases'], '...  \n",
       "\n",
       "[60407 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tmp['answers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Dataset.from_pandas(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "df = load_from_disk('/opt/ml/input/data/train_dataset/')\n",
    "df = pd.DataFrame(df['train'])\n",
    "type(df['answers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'document_id', '__index_level_0__'],\n",
       "    num_rows: 64359\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_datasets([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "def aug_data(data, new_data):\n",
    "    assert type(new_data) == DatasetDict, f'it mustnbe a Dataset type but you give {type(new_data)}'\n",
    "    train_df = Dataset.from_pandas(pd.DataFrame(new_data['train']))\n",
    "    validation_df = Dataset.from_pandas(pd.DataFrame(new_data['validation']))\n",
    "    train_data = concatenate_datasets([data['train'],train_df])\n",
    "    validation_data = concatenate_datasets([data['validation'],validation_df])\n",
    "    aug_dataset = DatasetDict({'train': train_data, 'validation' : validation_data})\n",
    "    return aug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_from_disk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m load_from_disk(\u001b[39m'\u001b[39m\u001b[39m/opt/ml/input/data/train_dataset/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39msquad_kor_v1\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_from_disk' is not defined"
     ]
    }
   ],
   "source": [
    "df = load_from_disk('/opt/ml/input/data/train_dataset/')\n",
    "dataset = load_dataset(\"squad_kor_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = aug_data(df, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 64359\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 6014\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features['answers'] # korquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].features['answers']   # competiotion MRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 60407\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48d21100d5443de975479b989b93023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60407 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'answers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m     example[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39manswer_start\u001b[39m\u001b[39m'\u001b[39m : Sequence(feature \u001b[39m=\u001b[39m example\u001b[39m.\u001b[39mfeatures[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfeature[\u001b[39m'\u001b[39m\u001b[39manswer_start\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m      4\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m : Sequence(feature \u001b[39m=\u001b[39m example\u001b[39m.\u001b[39mfeatures[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfeature[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m                             }\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m example\n\u001b[0;32m----> 7\u001b[0m dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(answer_change)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:2585\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2582\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2584\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2586\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2587\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2588\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2589\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2590\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2591\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2592\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2593\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2594\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2595\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2596\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2597\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2598\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2599\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2600\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2601\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2602\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2603\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2604\u001b[0m     )\n\u001b[1;32m   2605\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:585\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    586\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    587\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    588\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:552\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    546\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    547\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    548\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    549\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    550\u001b[0m }\n\u001b[1;32m    551\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    553\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    554\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:2967\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2965\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched:\n\u001b[1;32m   2966\u001b[0m     \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m-> 2967\u001b[0m         example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   2968\u001b[0m         \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   2969\u001b[0m             \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:2865\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   2864\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 2865\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   2866\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2867\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:2545\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2541\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m   2543\u001b[0m )\n\u001b[1;32m   2544\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> 2545\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2546\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m, in \u001b[0;36manswer_change\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manswer_change\u001b[39m(example):\n\u001b[0;32m----> 3\u001b[0m     example[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39manswer_start\u001b[39m\u001b[39m'\u001b[39m : Sequence(feature \u001b[39m=\u001b[39m example\u001b[39m.\u001b[39;49mfeatures[\u001b[39m'\u001b[39;49m\u001b[39manswers\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mfeature[\u001b[39m'\u001b[39m\u001b[39manswer_start\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m      4\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m : Sequence(feature \u001b[39m=\u001b[39m example\u001b[39m.\u001b[39mfeatures[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfeature[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m                             }\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m example\n",
      "\u001b[0;31mKeyError\u001b[0m: 'answers'"
     ]
    }
   ],
   "source": [
    "from datasets import Sequence\n",
    "def answer_change(example):\n",
    "    example['answers'] = {'answer_start' : Sequence(feature = example.features['answers'].feature['answer_start']),\n",
    "                        'text' : Sequence(feature = example.features['answers'].feature['text'])\n",
    "                            }\n",
    "    return example\n",
    "dataset['train'].map(answer_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].features['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df['train'].remove_columns(['document_id', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 60407\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 5774\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(df['train'].remove_columns(['document_id', '__index_level_0__']).features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Features' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfeatures([a])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Features' object is not callable"
     ]
    }
   ],
   "source": [
    "dataset['train'].features([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
