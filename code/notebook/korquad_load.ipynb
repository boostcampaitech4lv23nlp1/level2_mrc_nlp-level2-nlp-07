{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import DatasetDict, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/opt/ml/input/data/KorQuAD_2.1/train/korquad2.1_train_00.json','r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'data'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KorQuAD_2.0_train'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'url', 'context', 'raw_html', 'qas'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'url', 'context', 'raw_html', 'qas'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['data'][999].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "whole_list = []\n",
    "train_dict = {}\n",
    "answer_dict = {}\n",
    "c = 0\n",
    "for j in range(0,39):\n",
    "    file_j = ('0'+str(j))[-2:]\n",
    "    with open('/opt/ml/input/data/KorQuAD_2.1/train/korquad2.1_train_{}.json'.format(file_j),'r') as f:\n",
    "        train_data = json.load(f)\n",
    "        for i in range(len(train_data['data'])):\n",
    "            answers = train_data['data'][i]['qas'][0]\n",
    "            answer_dict['answer_start'] = [len(re.sub(' +', ' ', re.sub('(<([^>]+)>)', '', train_data['data'][i]['context'][:answers['answer']['answer_start']]).replace('\\n',' ').replace('\\t',' ')).lstrip())]\n",
    "            answer_dict['text'] = [re.sub(' +', ' ',re.sub('(<([^>]+)>)', '', answers['answer']['text']).replace('\\n',' ').replace('\\t',' ')).strip()]\n",
    "            count_id = ('000000' + str(c))[-6:]\n",
    "            train_dict['title']=train_data['data'][i]['title']\n",
    "            train_dict['context']=re.sub(' +', ' ',re.sub('(<([^>]+)>)', '', train_data['data'][i]['context']).replace('\\n',' ').replace('\\t',' ')).strip()\n",
    "            train_dict['question']=answers['question']\n",
    "            train_dict['id']='korquad-{}-{}'.format(file_j,count_id)\n",
    "            train_dict['answers']=answer_dict\n",
    "            train_dict['document_id']=int(answers['id'])\n",
    "            train_dict['__index_level_0__']=0\n",
    "            whole_list.append(train_dict)\n",
    "            answer_dict={}\n",
    "            train_dict={}\n",
    "            c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38496"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '뉴델리_메탈로-베타락타마제',\n",
       " 'context': '뉴델리 메탈로-베타락타마제 - 위키백과, 우리 모두의 백과사전 뉴델리 메탈로-베타락타마제 위키백과, 우리 모두의 백과사전. 둘러보기로 가기 검색하러 가기 대장균 (E.coli). NDM-1 유전자는 현재 일부 대장균 및 폐렴막대균 (Klebsiella pneumoniae)에서 발견되었다. 뉴델리 메탈로-베타락타마제 (New Delhi metalo-beta-lactamase, NDM-1)&#91;1&#93; 는 박테리아가 카바페넴 (carbapenem) 항생제에 내성을 갖게 하는 유전자이다. 산물은 베타락탐 가수분해 효소 (beta-lactamase) 중 하나인 카바페넴아제 (carbapenemase)다. 이 유전자를 가지고 있는 박테리아는 2010년 들어 언론 매체에서 슈퍼버그라는 이름으로 보도되고 있다.&#91;2&#93;&#91;3&#93; 아직까지 NDM-1을 막기 위한 항생제는 개발이 되지 않은 상태다.&#91;4&#93; 현재까지 이 유전자는 대장균 (E.coli)과 폐렴막대균 (Klebsiella pneumoniae) 일부 균주에서 발견되었으며, 수평적 유전자 이동 (horizontal gene transfer)을 통해 다른 균주 또는 종으로 넘어갈 수 있다. 목차 1 기능 2 기원과 전파 3 인도 측 반응 4 국내 상황 5 각주 6 외부 링크 기능[편집] 이 유전자는 베타-락탐계열 항생제를 가수분해하여 무효화시키는 효소 (enzyme)인 메탈로-베타락타마제 (metallo-beta-lactamase)를 생산한다. 이 항생제들은, 박테리아의 세포벽 (cell wall) 합성을 억제하여 최근까지만 해도 거의 대부분의 박테리아를 죽일 수 있는 것들이었다. 그러므로 이 유전자를 가진 박테리아는 종 간의 경쟁에서 살아남아, 우리 체내에서 더욱 강하게 번식하고 전파될 가능성이 있다. 다음 항생제는 이 효소에 의해 무효화된다: 세팔로스포린 계열 (cephalosporins) 페니실린 계열 (penicillins) 카바페넴 계열 (carbapenem) 기원과 전파[편집] 유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (Yong) 등이 처음 기록한 이 케이스의 환자가 인도에서 처음 박테리아 감염을 확인하였기 때문이다.&#91;5&#93; 박테리아 감염 치료가 뉴델리 병원에서 실패로 끝난 후 그는 모국 스웨덴으로 송환되었으며, 그곳에서 카바페넴에 내성을 보이는 폐렴막대균의 유전자가 분리되었다. 용 등은 이 내성 메커니즘이 \"분명히 인도에서 생겨났으나, 이것이 얼마나 퍼져있는지를 보여주는 데이터가 인도에 존재한다\"라고 주장하였다.&#91;5&#93; 보고된 바에 따르면 이 유전자는 파키스탄, 인도, 그리고 여러 아시아 국가에서 발견되었으며 이곳 병원에 입원했던 사람들에 의해 유럽으로 옮겨졌다. 그 중 대다수는 저가의 성형 수술을 위해 의료 관광을 떠났다가 수술 중 감염이 된 사람들이었다. 2010년 6월까지, 미국 내에서 이런 내성을 가진 장내세균과 (Enterobacteriaceae) 균주가 세 건이 보고되었으며, CDC는 \"세 건의 보고된 환자 모두 인도에서 최근 의료 서비스를 받고 온 사람\"이라고 밝혔다.&#91;6&#93; 하지만, 미 전문가들은 이 균주가 이미 미국에서 흔한 내성균들, 대표적으로 MRSA보다 더 위험성이 큰 지는 확실치 않다고 얘기하였다.&#91;7&#93; 2010년 8월, 저널 The Lancet Infectious Diseases에 최근 행해진 다국적 연구 결과가 실린 바 있다. 이 연구는 NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석하였다. 연구에 사용된 케이스는 영국 37건, 첸나이 26건, 인도 하리아나 주 26건, 그 외 인도, 파키스탄의 여러 지역 73건 등이었다.&#91;1&#93; 저자의 말에 따르면, 많은 균주들이 NDM-1 유전자를 플라스미드 상에 가지고 있었으며, 이 때문에 균과 균 사이의 유전자 전달 (gene transfer)이 쉽게 가능할 것으로 보았다. 연구 시 다뤄진 모든 균주는 베타-락탐계열 항생제, 퀴놀론 (quinolone) 계열 항생제, 아미노글리코사이드 등 여러 항생제에 내성을 보였으나, 대부분 폴리믹신 (polymyxin) 계열 항생제 콜리스틴 (colistin)에는 감수성을 보였다. 2010년 8월 초 화합물 GSK-299423이 이러한 박테리아들의 번식을 막아 유의한 효과를 보여주어, 현재로써는 NDM-1 치료의 유망주로 떠오르고 있다.&#91;8&#93; 인도 측 반응[편집] 인도 보건부는 이 유전자가 인도나 파키스탄에서 기원하였다는 결론에 대해, \"말도 안 된다\" (unfair) 며 반박에 나섰으며, 인도 병원은 안전한 치료 환경을 갖추고 있다고 주장하였다.&#91;9&#93; 인도 정치인들은 이 내성 유전자와 인도를 연관짓는 것을 \"악의적인 선전 활동\" (malicious propaganda)이라며 이른바 \\'선택적인 악의\\'를 띈 다국적 기업을 비판하고 나섰다.&#91;9&#93;&#91;10&#93; 바라티야 자나타 당의 한 정치인은 인도를 유전자의 기원으로 주장한 논문을 가짜라며 이는 인도의 의료 관광객을 겁주어 쫓아버리려는 음모라고 말하였다.&#91;11&#93; 인도 보건부는 유전자에 \"뉴델리\"란 이름을 붙인 것에 대해서 공식적으로 강한 불쾌감을 표하였다.&#91;12&#93; 한편, Journal of Association of Physicians of India 2010년 3월 호에 실린 논평에서는 이 유전자가 생겨난 것을 인도 건강 관리 체제 내에 퍼진 무분별한 항생제 사용의 탓으로 돌리며, \"인도 의사들은 아직 항생제 내성의 문제를 심각하게 받아들이지 못하고 있다\"라는 말과 함께 의사, 약사들의 항생제 처방에 법적 제한이 거의 없음을 지적하고 나섰다.&#91;13&#93; Times of India에서는 인도는 항생제 사용과 항생제 내성 감염에 대한 대처 방안의 개선이 필요하다는 데에는 전문가들 간의 이견이 없다고 주장하였다.&#91;14&#93; 2010 Lancet 연구에 참여했던 주 저자는, 무작정 인도 내에서 치료를 피하는 것은 동의하지 않는다고 말하였다.&#91;14&#93; 국내 상황[편집] 2010년 8월 질병관리본부는 대한민국 내에 \"현재까지 국내에서는 NDM-1을 생산하는 대장균과 폐렴막대균종이 검출된 사례는 없다\"고 밝혔다. 현재 전국 종합병원과 27개 대학병원 진단검사의학과를 중심으로 NDM-1 생산 장내세균과를 포함한 주요 내성균 모니터링 사업이 운영 중이다.&#91;15&#93; 2010년 10월 해외여행을 가지 않은 국내인이 4명 NDM-1 감염 확인. 각주[편집] ↑ 가 나 Kumarasamy et. al. (2010). &#8220;Emergence of a new antibiotic resistance mechanism in India, Pakistan, and the UK: a molecular, biological, and epidemiological study&#8221;. &#12298;The Lancet Infectious Diseases&#12299;. doi:10.1016/S1473-3099(10)70143-2.&#160; ↑ 이, 주상 (2010년 8월 13일). &#8220;초강력 박테리아 \\'슈퍼버그\\'…항생제도 안 통해&#8221;. SBS. 2010년 8월 13일에 확인함.&#160; ↑ Jordan, Carol (2010년 8월 11일). &#8220;World update: More aid planned for Pakistan&#8221;. CNN. 2010년 8월 13일에 확인함.&#160; ↑ Globe and Mail: Scientists find new superbug spreading from India ↑ 가 나 Yong D, Toleman MA, Giske CG, Cho HS, Sundman K, Lee K, Walsh TR. (2009년 12월). &#8220;Characterization of a new metallo-beta-lactamase gene, bla(NDM-1), and a novel erythromycin esterase gene carried on a unique genetic structure in Klebsiella pneumoniae sequence type 14 from India&#8221;. &#12298;Antimicrob Agents Chemother.&#12299; 53 (12): 5046-54. PMC&#160;2786356. PMID&#160;19770275. doi:10.1128/AAC.00774-09.&#160; 더 이상 지원되지 않는 변수를 사용함 (도움말) CS1 관리 - 여러 이름 (링크) ↑ Detection of Enterobacteriaceae Isolates Carrying Metallo-Beta-Lactamase --- United States, 2010 ↑ McNeil Jr., Donald G. (2010년 8월 11일). &#8220;Antibiotic-Resistant Bacteria Moving From South Asia to U.S.&#8221;. &#12298;The New York Times&#12299;. 2010년 8월 13일에 확인함.&#160; ↑ Alazraki, Melly (2010년 8월 6일). &#8220;GlaxoSmithKline Finds Compound That Could Help Fight \\'Superbugs\\'&#8221;. &#12298;dailyfinance.com&#12299;. 2010년 8월 16일에 원본 문서에서 보존된 문서. 2010년 8월 13일에 확인함.&#160; ↑ 가 나 Pandey, Geeta (2010년 8월 12일). &#8220;India rejects UK scientists\\' \\'superbug\\' claim&#8221;. &#12298;BBC&#12299;. 2010년 8월 13일에 확인함.&#160; ↑ &#8220;Linking India to superbug unfair and wrong, says India&#8221;. &#12298;Hindustan Times&#12299;. 2010년 8월 12일. 2010년 8월 14일에 원본 문서에서 보존된 문서. 2010년 8월 13일에 확인함.&#160; ↑ \\'Superbug\\' an MNC conspiracy: BJP leader | SS Ahluwalia | superbug | Indian Express&#91;깨진 링크(과거 내용 찾기)&#93; ↑ Sharma, Sanchita (2010년 8월 13일). &#8220;‘Don’t blame superbug on India, it’s everywhere’&#8221;. &#12298;Hindustan Times&#12299;. 2010년 8월 14일에 원본 문서에서 보존된 문서. 2010년 8월 13일에 확인함.&#160; ↑ Abdul Ghafur K (2010년 3월). &#8220;An obituary- On the Death of antibiotics!&#8221;. &#12298;Journal of Association of Physicians of India&#12299; 58.&#160; 더 이상 지원되지 않는 변수를 사용함 (도움말) ↑ 가 나 Narayan, Pushpa (2010년 8월 13일). &#8220;Indian author says superbug report is fudged&#8221;. &#12298;The Times of India&#12299;. 2010년 8월 13일에 확인함.&#160; ↑ 송, 병기 (2010년 8월 13일). &#8220;`슈퍼버그` 국내 유입 아직 없어&#8221;. &#12298;MK뉴스&#12299;. 2010년 8월 13일에 확인함.&#160; 외부 링크[편집] BBC News Health - NDM-1 슈퍼버그에 대한 질문과 답변 National Resistance Alert 3 addendum in UK (PDF) NDM-1 슈퍼버그에 대한 스웨덴 뉴스 원본 주소 \"https://ko.wikipedia.org/w/index.php?title=뉴델리_메탈로-베타락타마제&amp;oldid=24016037\" 분류: 세균학유전자EC 3.5.2숨은 분류: 인용 오류 - 오래된 변수를 사용함CS1 관리 - 여러 이름깨진 링크를 가지고 있는 문서 둘러보기 메뉴 개인 도구 로그인하지 않음토론기여계정 만들기로그인 이름공간 문서토론 변수 보기 읽기편집역사 보기 더 보기 검색 둘러보기 대문사용자 모임요즘 화제최근 바뀜모든 문서 보기임의 문서로도움말기부 도구 여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기특수 문서 목록고유 링크문서 정보위키데이터 항목이 문서 인용하기 인쇄/내보내기 책 만들기PDF로 다운로드인쇄용 판 다른 언어 ČeštinaDeutschEnglishEspañolSuomiFrançaisעבריתItaliano日本語MalagasyनेपालीNederlandsPolskiPortuguêsРусскийSrpskohrvatski / српскохрватскиСрпски / srpskiSvenskaTürkçeTiếng Việt中文 링크 편집 이 문서는 2019년 4월 12일 (금) 13:49에 마지막으로 편집되었습니다. 모든 문서는 크리에이티브 커먼즈 저작자표시-동일조건변경허락 3.0에 따라 사용할 수 있으며, 추가적인 조건이 적용될 수 있습니다. 자세한 내용은 이용 약관을 참고하십시오.Wikipedia®는 미국 및 다른 국가에 등록되어 있는 Wikimedia Foundation, Inc. 소유의 등록 상표입니다. 개인정보 정책 위키백과 소개 면책 조항 개발자 쿠키 정책 모바일 보기',\n",
       " 'question': '뉴델리 메탈로 베타락타마제의 이름은 어느 지역에서 유래되어 정해졌는가?',\n",
       " 'id': 'korquad-38-038495',\n",
       " 'answers': {'answer_start': [1022], 'text': ['뉴델리']},\n",
       " 'document_id': 105688,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_list[38495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/input/data/KorQuAD_2.1/train/train.json','w') as outfile:\n",
    "    json.dump(whole_list,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dev_list = []\n",
    "train_dict = {}\n",
    "answer_dict = {}\n",
    "c = 0\n",
    "for j in range(0,5):\n",
    "    file_j = ('0'+str(j))[-2:]\n",
    "    with open('/opt/ml/input/data/KorQuAD_2.1/dev/korquad2.1_dev_{}.json'.format(file_j),'r') as f:\n",
    "        train_data = json.load(f)\n",
    "        for i in range(len(train_data['data'])):\n",
    "            answers = train_data['data'][i]['qas'][0]\n",
    "            answer_dict['answer_start'] = [len(re.sub(' +', ' ', re.sub('(<([^>]+)>)', '', train_data['data'][i]['context'][:answers['answer']['answer_start']]).replace('\\n',' ').replace('\\t',' ')).lstrip())]\n",
    "            answer_dict['text'] = [re.sub(' +', ' ',re.sub('(<([^>]+)>)', '', answers['answer']['text']).replace('\\n',' ').replace('\\t',' ')).strip()]\n",
    "            count_id = ('000000' + str(c))[-6:]\n",
    "            train_dict['title']=train_data['data'][i]['title']\n",
    "            train_dict['context']=re.sub(' +', ' ',re.sub('(<([^>]+)>)', '', train_data['data'][i]['context']).replace('\\n',' ').replace('\\t',' ')).strip()\n",
    "            train_dict['question']=answers['question']\n",
    "            train_dict['id']='korquad-{}-{}'.format(file_j,count_id)\n",
    "            train_dict['answers']=answer_dict\n",
    "            train_dict['document_id']=int(answers['id'])\n",
    "            train_dict['__index_level_0__']=0\n",
    "            dev_list.append(train_dict)\n",
    "            answer_dict={}\n",
    "            train_dict={}\n",
    "            c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/input/data/KorQuAD_2.1/train/valid.json','w') as outfile:\n",
    "    json.dump(dev_list,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '퍼블릭_라이브러리_오브_사이언스',\n",
       " 'context': '퍼블릭 라이브러리 오브 사이언스 - 위키백과, 우리 모두의 백과사전 퍼블릭 라이브러리 오브 사이언스 위키백과, 우리 모두의 백과사전. 둘러보기로 가기 검색하러 가기 Public Library of Science (PLoS) 주소 http://www.plos.org/ 퍼블릭 라이브러리 오브 사이언스(Public Library of Science, PLoS)는 의약 분야 오픈 액세스 출판사이다. 2000년 10월에 연구자들이 만든 단체로서 형성 초기에는 주로 오픈 액세스 라이선스 개발과 지지자들로부터 서명 받기 등 오픈 액세스 확산 운동을 이끌었으며, 2003년부터는 Plos Biology 등 몇 종의 학술지를 창간하면서 출판을 시작하였다. 논문심사 및 편집업무 등에 소요되는 비용을 저자와 연구지원 기관에 부과하고, 이용자에게 논문을 오픈 액세스 방식으로 제공하고 있다.&#91;1&#93; PLoS는 비영리 기관으로서 오픈 액세스 출판의 확산을 위하여 그것의 성공례를 제시하는 것을 궁극적인 목적으로 하고 있다. 이용자들은 원저자를 밝힐 경우 상업적 혹은 비상업적으로 저작물을 복제, 배포, 전시, 공연할 수 있고 2차 저작물을 생성할 수 있게 된다.&#91;1&#93; 목차 1 추진활동 2 저널 3 의도 4 목적 5 분야 6 사용 기술 7 개인 정보 보호 정책 8 운영 9 출판 비용의 지원 10 자유이용의 발전 11 각주 12 외부 링크 추진활동[편집] 전 세계 과학 및 의약분야 문헌이 공공자원이 되어야한다고 주장하는 과학자들의 연합으로 2000년에 조직되었다. 처음 활동으로는 과학기술분야 출판사들에게 그들이 보유하고 있는 과학기술분야 공공도서관에서 이용할 수 있도록 설득하는 일이었다. 이를 위하여 과학자들은 출판사들을 대상으로 공개편지를 보내 학술지에 수록된 논문들이 출판 후 6개월 이내에 PubMed Central과 같은 온라인 공공도서관을 통해 무료로 배포될 수 있도록 촉구하는 활동을 벌였다. 2013년 현재 180개국 34,000 여명의 과학자들이 참가하고 있다. PLoS 추친활동은 과학기술분야 출판사로부터 연구논문의 자유로운 이용에 대한 중요하고 환영할 만한 발전을 도출하기도 하였지만, 전체적인 출판사의 반응은 PLoS의 기대 목표에 미치지 못하였다. 2001년 여름, PLoS는 본래 취지를 발전시킬 방법으로 PLoS 저널의 창간을 결정하게 되었고, 오픈 액세스 출판에 대한 새로운 모델을 제시하였다. 2001년 여름, PLoS는 본래의 취지를 발전시킬 방법으로 PLoS 저널의 창간을 결정하게 되었고, 오픈 액세스 출판에 대한 새로운 모델을 제시하였다. 2002년 12월 PLoS는 Gordon Betty Moore 재단으로부터 $9M의 기금을 조성하였고, 이 기금을 바탕으로 비영리 과학기술벤처를 출범시켰다. 2003년 10월 첫 저널인 PLoS Biology부터 PloS Medicine PLOS Genetics, PLOS Pathogens, PLOS Computational Biology이 간행됐으며, 최신 간행 저널로는 2007년에 Bill &amp; Melinda Gates Foundation의 후원을 통해 PLOS Neglected Tropical Diseases이 간행되었다.&#91;2&#93;&#91;3&#93; 저널[편집] 2003.10. PLoS Biology 출간&#91;3&#93; 2004.10. PloS Medicine 출간&#91;3&#93; 2005. PLOS Genetics, PLOS Pathogens, PLOS Computational Biology 출간&#91;3&#93; 2007. PLOS Neglected Tropical Diseases 출간&#91;3&#93; 의도[편집] 오픈 액세스 학술지 성공례창출 타 출판사 오픈 액세스 모델 도입 격려&#91;1&#93; 목적[편집] 온라인상에 과학분야 공공도서관을 구축하는 것을 목적으로 한다. 저자 및 출판사들이 그들 저작물에 대한 저작권을 보유하되, 그 저작물이 복제되거나 재배포될 때 적절한 귀속이 주어진다는 조건하에서, 공공영역에 대해 이용허락을 하는 것이다. &#91;4&#93; 분야[편집] 생물학, 의학&#91;1&#93; 사용 기술[편집] PLOS에서 사용하는 기술인 암브라(Ambra)는 오픈 액세스 연구 논문을 공개하는 혁신적인 오픈 소스 운영체제이다. 이것은 이용자가 콘텐츠와 상호 작용하여 자료가 \"살아있는\"자료가 될 수있도록 포스트 간행 주석과 면담을 위한 기능을 제공한다. 암브라 플랫폼은 지금도 PLOS에서 활발하게 개발되고 있으며, 아파치 라이선스 버전 2.0 에서 허가 된다. 구체적으로 살펴보자면 암브라에 연계되는 오픈 소스 애플리케이션을 보자면 응용 프로그램 문서 자체에 게시 된 기사의 사용과 범위에 대한 정보를 표시하기 위하여 개발된 기사 수준의 메트릭스(Article-Level Metrics)가 있다. 이는 온라인으로 사용, 견적, 소셜 북마크, 메모, 의견, 평가 및 블로그 커버리지를 포함한 연구 논문의 집계 관련 데이터와 통계를 표현하는 것에 사용되고 있다. PLOS의 모든 저널 및 컬렉션은 암브라 플랫폼에 관리되지만 예외적으로 생물다양성(Biodiversity)은 라이프레이 포탈 플랫폼에 연결되고 PLOS에 상반되는 경향은 구글 놀에 의해 관리된다. 2011년 여름, 두가지 새로운 전개방법이 생겼는데&#160;ALM과 API를 접목하여 컨텐츠와 상호작용방식을 개선하고 애플리케이션의 생성을 촉진하는 방법과 유명한 레퍼런스 매니저로서 대학 소셜 네트워크에 활용되고 있는 Mendeley에 합류하여 애플리케이션 개발을 촉진하는 것이 그것이다.&#91;5&#93; 개인 정보 보호 정책[편집] 개인 정보의 수집 어떤 상황에서 PLOS는 사용자의 이름, 전자 메일 주소, 기관명, 전화 번호 등 귀하의 개인 정보를 요구할 수 있다. 그러나 수집에 대한 응답은 자발적이다. PLOS는 전자 자원과 인터페이스를 사용자에 맞게 지정하기 위해 정보를 수집한다. 일반적으로는 개인 정보의 누출 없이 사이트 이용이 가능하다. 이 질문에 대한 응답이 엄격하게 자발적이다. 그러나 일반적으로는 개인정보 제공과 관계 없이 사이트 방문과 이용이 가능하다. 도메인 정보 수집 PLOS는 사이트 이용 분석의 일부로 도메인 정보를 수집한다. 이 데이터는 고객들이 방문하는 빈도를, 기 사이트를 방문하고 그들이 가장 자주 방문하는 사이트의 일부와 유사성 등을 분석하는 것을 허용한다. PLOS는 Web 기반의 제품을 개선하기 위해 이 정보를 사용한다. 이 정보는 자동으로 수집되므로 이용자의 작업을 요하지는 않는다. 제 삼자에게의 공개 기 사이트는 개인 및 기밀 정보로 독자의 정보를 처리하고, 법에 의해 요구되거나 귀하의 명시적인 허가가 아닌 이상 제 3 자에 정보를 공개하지 않는다. 쿠키의 사용 이 사이트의 일부 페이지는 사이트가 식별 목적을 위해 하드 드라이브에 배치하는 작은 파일인 쿠키를 사용할 수 있다. 이러한 파일은 이용자가 또 다시 기 사이트를 방문할 때에 현장 등록 및 사용자 정의에 \\u200b\\u200b사용된다. 이용자는 쿠키 수집을 위해 하드 드라이브의 데이터를 읽을 수 있음을 유의해야한다. 웹 브라우저가 쿠키를 받을 때, 이용자는 그것을 수락하거나 하지 않는 선택을 제공, 통지 할 수 있다. 하지만 쿠키를 허용함으로써 일부 페이지는 완벽하게 작동하지 않을 수 있다. 그래서 이용자는 이 사이트의 특정 정보에 액세스 할 수 없을 경우가 생긴다. 정책은 수시로 변경될 수 있으며, 정보가 사용되는 방법에 대한 우려나 개인보호 정책에 대한 질문이 있다면 PLOS 측으로 문의할 수 있다.&#91;6&#93; 운영[편집] PLoS는 년회비와 출판비 할인율에 따라 6가지 유형의 회원 제도를 운영하는데, BMC 출판사의 경우처럼 반드시 출판에 소요된 비용을 회수하기 위한 것만은 아니다. 즉, PLoS는 대학, 연구지원기관 등이 PLoS의 오픈 액세스 확산 노력을 지지할 수 있는 하나의 채널을 마련하고, 이들 지지 기관 소속 연구원들에게 APC할인혜택을 주기 위하여 회원 제도를 운영하고 있다, &#91;1&#93; 출판 비용의 지원[편집] 오픈 액세스형 출판기관인 PLoS(Public Library of Science)는 연구자의 논문이 채택되었을 경우 출판 비용을 요구하며, 만일 연구자가 출판 비용을 부담하기 힘든 경우에는 출판비용의 전체를 보류하거나 가능한 액수만큼 지불하는 것을 결정할 수 있다. &#91;7&#93; 자유이용의 발전[편집] PloS(2003)는 과학 발전, 교육 및 공공의 이익을 위해 전 세계 과학자 및 대중이 전 세계의 과학 및 의학 문헌에 무료로 접근 할 수 있도록 하자는 취지에서 2000년 10월 과학자들에 의해 결성된 비영리 조직이다. 출판된 과학 논문의 모든 내용을 아카이브하여 배포하기 위한 국제적인 차원의 온라인 과학 공공도서관을 구축하고, 현재 수백만의 개별 논문들과 수 천의 서로 다른 학술잡지에 분산되어 있는 정보들을 연결하여 통합시키는 방법을 모색하고 있다. 이러한 목표의 일환으로 전 세계 과학자들은 출판사에게 학술잡지에 실린 연구 논문들이 출판 후 6개월 이내에 독립적인 온라인 공공도서관에 무료로 배포될 수 있도록 촉구하는 공개 편지를 회람시키고있다. 공개 편지의 내용은 출판사들이 자신의 콘텐츠를 중앙저장소에 제출하지 않는 경우 해당 출판사의 출판물에는 글을 싣거나, 심사하거나, 구독하지 않겠다는 서약이다. 이에 대한 국제적인 과학집단의 반응은 놀라운 것으로서 매우 긍정적이었다. 2002년 현재 공개 편지는 182개국으로부터 31,079명의 서명을 얻어 내었다. 반면에 출판사 측의 반응은 아직 더디게 나타나고 있다. 자신의 저작물에 자유롭게 접근하고 이용할 수 있도록 하는 저자의 경우, 어떻게하면 해당 저작에 대한 적절한 보상을 받으면서 이를 수행할 수 있을 것인지에 대해 과학자들과 출판사, 그리고 저작권 전문가들이 심도 깊은 논의를 나누었다. 그 결과 최선의 방법은 저자나 출판사가 저작에 대한 저작권을 보유하되 해당 저작이 재생산되거나 재배포될 때는 언제든지 적절한 보상을 해준다는 조건 하에 저작을 공적으로 이용할 수 있도록 허가하자는 것이다. 저작권을 보유함으로써 저자와 이들을 대표해 주는 사람들은 라이선스를 강화할 수 있는 권리는 갖게 되지만, 저작이 어떻게 누구에 의해 이용될 것인지를 지적할 권리는 갖지 않는다. 2002년 12월 17일 PloS는 비영리의 국제적인 \"풀뿌리\" 과학자 조직으로서 과학 연구의 출판물을 과학자와 물리학자 및 공공에게 더욱 유용하게 이용될 수 있도록 새로운 과학 출판 벤처를 출범시킨다는 발표를 하였다. 이러한 새로운 움직임은 Gordon and Betty Moore Foundation으로부터 5년간 9백만 달러의 기금을 지원 받게 되었고 Howard Hughes Medial Institute로부터의 중대한 정책 결정을 받게 된다. PloS는 현재 두 종류의 저널 출판을 계획하고 있다. 하나는 2003년 10월에 나올 예정인 PloS Biology이며 또 하나는 2004년에 나올 예정인 PloS Medicine이다. 새 저널에 대한 선임 출판진은 국제적으로 권위를 갖고 있는 과학자들이다. PloS 저널은 활발한 동료집단 평가라든가 수준 높은 편집 기준 등과 같은 과학 저널로서의 주요 특질들은 모두 보유할 것이나, 이런 서비스 비용은 개별 출판 논문에 대한 적절한 비용으로 처리되는 새로운 비즈니스 모델을 이용하게 될 것이다. 이 새로운 모델은 이용 비용이라든가 PloS가 모든 출판물을 다시 재분배하는 데 따른 제한 없이 즉시 온라인 상으로 이용할 수 있도록 할 것이다.&#91;8&#93; 각주[편집] ↑ 가 나 다 라 마 , 정경희. 2006. 의학 분야 오픈 액세스 현황 분석을 통한 국내 의학 정보 활성화 방안. 『한국문헌정보학회지』. 40(2):389-414. ↑ , 최재황, 조현양. 2005. 오픈 액세스 운동의 동향과 학술적 이해관계자의 대응전략. 『정보관리학회지』. 22(3):307-326. ↑ 가 나 다 라 마 http://www.plos.org/about/what-is-plos/publishing/ ↑ 정경희. 2002. 정보공유적 모델 기반의 학술커뮤니케이션에 대한 연구: 저작권을 중심으로. 『정보관리학회지』. 19(4):393-394. ↑ &#8220;PLOS Homepage&#8221;. 2013년 6월 11일에 확인함.&#160; ↑ &#8220;PLOS 홈페이지&#8221;. 2013년 6월 14일에 확인함.&#160; ↑ 노류하, 2005, 오픈 액세스 환경에서의 저작권 문제에 대한 연구&#160;: 생물정보학 연구자들의 인식을 중심으로, 부산대학교 대학원, 학위논문(석사), p18-19. ↑ 이두영,황옥경, 학술 커뮤니케이션의 새로운 동향&#160;: 자유이용을 중심으로, 정보 관리연구 vol.34, no.2, 2003, pp.1-23 외부 링크[편집] 위키미디어 공용에 관련된미디어 분류가 있습니다.퍼블릭 라이브러리 오브 사이언스 퍼블릭 라이브러리 오브 사이언스 - 공식 웹사이트 Harold Varmus iBioMagazine talk about PLoS: \"Changing the Way We Publish\" Editorial in the 7 August 2003 edition of The New York Times concerning Public Library of Science journals vdeh오픈 액세스 개념 학술지 과학 학술지 출판 전 논문 논문처리비용 성명 부다페스트 오픈 액세스 이니셔티브 NIH 퍼블릭 액세스 정책 전략 오픈 액세스 (\"골드 OA\" ) 셀프 아카이빙 (\"그린 OA\" ) 오픈 액세스 정책 의무제출 프로젝트 및 단체 크리에이티브 커먼즈 DOAJ 퍼블릭 라이브러리 오브 사이언스 사이허브 오픈 콘텐츠 - 오픈 데이터 - 열린 교육 - 열린 정부 - 오픈 하드웨어 - 오픈 날리지 - 오픈 사이언스 - 오픈 소스 원본 주소 \"https://ko.wikipedia.org/w/index.php?title=퍼블릭_라이브러리_오브_사이언스&amp;oldid=24197478\" 분류: 생물학 학술지미국의 출판사샌프란시스코의 단체숨은 분류: 한국어 위키백과의 링크가 위키데이터와 다른 위키공용분류위키데이터와 위키백과에서 차이가 있는 공식 웹사이트 둘러보기 메뉴 개인 도구 로그인하지 않음토론기여계정 만들기로그인 이름공간 문서토론 변수 보기 읽기편집역사 보기 더 보기 검색 둘러보기 대문사용자 모임요즘 화제최근 바뀜모든 문서 보기임의 문서로도움말기부 도구 여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기특수 문서 목록고유 링크문서 정보위키데이터 항목이 문서 인용하기 다른 프로젝트 위키미디어 공용 인쇄/내보내기 책 만들기PDF로 다운로드인쇄용 판 다른 언어 العربيةCatalàDeutschEnglishEspañolSuomiFrançaisעבריתItaliano日本語မြန်မာဘာသာNederlandsPolskiPortuguêsРусскийSvenskaதமிழ்Українська中文 링크 편집 이 문서는 2019년 5월 11일 (토) 23:32에 마지막으로 편집되었습니다. 모든 문서는 크리에이티브 커먼즈 저작자표시-동일조건변경허락 3.0에 따라 사용할 수 있으며, 추가적인 조건이 적용될 수 있습니다. 자세한 내용은 이용 약관을 참고하십시오.Wikipedia®는 미국 및 다른 국가에 등록되어 있는 Wikimedia Foundation, Inc. 소유의 등록 상표입니다. 개인정보 정책 위키백과 소개 면책 조항 개발자 쿠키 정책 모바일 보기',\n",
       " 'question': '과학 및 의약분야 문헌이 공공자원 되어야한다고 주장하는 과학자들의 연합은 몇 년도에 조직되었는가?',\n",
       " 'id': 'korquad-04-004700',\n",
       " 'answers': {'answer_start': [757], 'text': ['2000년']},\n",
       " 'document_id': 106632,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_list[4700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5f30fd53ca4be2a5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /opt/ml/.cache/huggingface/datasets/json/default-5f30fd53ca4be2a5/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5102.56it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 925.08it/s]\n",
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /opt/ml/.cache/huggingface/datasets/json/default-5f30fd53ca4be2a5/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "ds = datasets.Dataset.from_json('/opt/ml/input/data/KorQuAD_2.1/train/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-56fe0ff52f29f51d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /opt/ml/.cache/huggingface/datasets/json/default-56fe0ff52f29f51d/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4544.21it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 811.28it/s]\n",
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /opt/ml/.cache/huggingface/datasets/json/default-56fe0ff52f29f51d/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dv = datasets.Dataset.from_json('/opt/ml/input/data/KorQuAD_2.1/dev/valid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'드라마 예고범의 감독은 누구일까?'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['context'][0][2420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds['title'])):\n",
    "    if ds['context'][i][ds['answers'][i]['answer_start'][0]] != ds['answers'][i]['text'][0][0]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_start': [2420], 'text': ['나카무라 요시히로, 히라바야시 카츠토시, 사와다 메구미']}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 3952\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "    num_rows: 42448\n",
       "})"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.concatenate_datasets([train_dataset['train'],ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 38496\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 4736\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetDict({'train' : ds, 'validation' : dv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
