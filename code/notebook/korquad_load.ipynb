{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import DatasetDict, load_from_disk, Dataset, concatenate_datasets\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/opt/ml/input/data/KorQuAD_2.1/train/korquad2.1_train_00.json','r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'data'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KorQuAD_2.0_train'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'url', 'context', 'raw_html', 'qas'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'url', 'context', 'raw_html', 'qas'])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['data'][999].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://zeany.net/46\n",
    "def preprocess_context(example):\n",
    "    body = re.sub('<title.*?>.*?</title>', '', example, 0, re.I|re.S)\n",
    "    body = re.sub('<table.*?>.*?</table>', '', body, 0, re.I|re.S)\n",
    "    body = re.sub('<td.*?>.*?</td>', '', body, 0, re.I|re.S)\n",
    "    body = re.sub('<li.*?>.*?</li>', '', body, 0, re.I|re.S)\n",
    "    body = re.sub('<ol.*?>.*?</ol>', '', body, 0, re.I|re.S)\n",
    "    text = re.sub('<.+?>', '', body, 0, re.I|re.S)\n",
    "    text = text.replace(\"[편집]\",\"\")\n",
    "    text = text.split(\"같이 보기\")[0]\n",
    "    text = text.split(\"참고 자료\")[0]\n",
    "    text = text.split(\"외부 링크\")[0]\n",
    "    text = text.split(\"원본 주소\")[0]\n",
    "    text = text.split(\"각주\")[0]\n",
    "    text = text.split(\"참고 문헌\")[0]\n",
    "    text = text.split(\"함께 보기\")[0]\n",
    "    text = text.split(\"관련 서적\")[0]\n",
    "    text = text.split(\"관련 항목\")[0]\n",
    "    space = re.sub('&nbsp;| |\\t|\\r|\\n|\\xa0', ' ', text)\n",
    "    one_space = re.sub(' +', ' ', space)\n",
    "    return one_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "whole_list = []\n",
    "train_dict = {}\n",
    "answer_dict = {}\n",
    "c = 0\n",
    "for j in range(0,39):\n",
    "    file_j = ('0'+str(j))[-2:]\n",
    "    with open('/opt/ml/input/data/KorQuAD_2.1/train/korquad2.1_train_{}.json'.format(file_j),'r') as f:\n",
    "        train_data = json.load(f)\n",
    "        for i in range(len(train_data['data'])):\n",
    "            answers = train_data['data'][i]['qas'][0]\n",
    "            answer_dict['answer_start'] = [len(preprocess_context(train_data['data'][i]['context'][:answers['answer']['answer_start']]).lstrip())]\n",
    "            answer_dict['text'] = [preprocess_context(answers['answer']['text']).strip()]\n",
    "            count_id = ('000000' + str(c))[-6:]\n",
    "            train_dict['title']=train_data['data'][i]['title']\n",
    "            train_dict['context']= preprocess_context(train_data['data'][i]['context']).strip()\n",
    "            train_dict['question']=answers['question']\n",
    "            train_dict['id']='korquad-{}-{}'.format(file_j,count_id)\n",
    "            train_dict['answers']=answer_dict\n",
    "            train_dict['document_id']=int(answers['id'])\n",
    "            train_dict['__index_level_0__']=0\n",
    "            if len(answer_dict['text'][0])>0:\n",
    "                if (len(train_dict['context']) <= 2000)&(len(answer_dict['text']) <= 80):\n",
    "                    if len(train_dict['context']) > answer_dict['answer_start'][0]:\n",
    "                        if train_dict['context'][answer_dict['answer_start'][0]] != answer_dict['text'][0][0]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            whole_list.append(train_dict)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            answer_dict={}\n",
    "            train_dict={}\n",
    "            c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12876"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2000\n",
      "2000 4000\n",
      "4000 6000\n",
      "6000 8000\n",
      "8000 10000\n",
      "10000 12000\n",
      "12000 14000\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(range(0,14000,2000)):\n",
    "    with open('/opt/ml/input/data/KorQuAD_2.1/train/preprocessed/train_under2000_{}.json'.format(idx),'w') as outfile:\n",
    "        json.dump(whole_list[i:i+2000],outfile)\n",
    "        print(i,i+2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '이봉조',\n",
       " 'context': '생애 경상남도 남해에서 출생하였고 지난날 한때 경상남도 진주에서 잠시 유아기를 보낸 적이 있는 그는 일찍이 미국의 재즈 음악에 심취하였다. 진주고등보통학교를 졸업한 후 1952년 한양공대 건축공학과에 입학했다. 대학 시절이던 1954년부터 미8군에서 취미 활동으로 재즈 색소폰을 연주 및 공연하였으며 2년간 휴학한 뒤 1958년 대학을 나왔다. 서울특별시청 토목과 공무원으로 재직하면서 틈틈이 미8군 무대에서 재즈 테너 색소폰을 연주하며 테너 색소포니스트 엄토미(嚴吐美)의 문하생으로서 단연 두각을 나타내었다. 1961년 서울특별시청 공무원직에서 퇴직하였고 그 후 주직업적으로 재즈 음악가의 길을 걸었다. 작곡가의 입장으로써는 현미(玄美), 정훈희(鄭薰姬) 등의 가수를 발굴하였고 뮤지컬 배우 출신의 윤복희(尹福姬)를 훈련시켜 가수로 재발탁하였다. 1963년에는 영화 《가정교사》로 영화 음악감독 데뷔하였다. 1965년 영화 《광야의 호랑이》로 영화 음악연출가 데뷔하였으며 1967년 영화 《안개》로 영화음악연주감독 데뷔했다. 그 후 1970년대에는 여러 국제가요제에서도 작곡가로써 자신의 명성을 떨쳤으며 개신교 신자라는 입장으로 색소폰 연주곡 CCM 가스펠 음반도 다수 발표하였다. 그는 부인 노전숙과 연애 끝에 1956년 결혼하였고 3남 3녀를 낳았다. 순탄할줄 알았던 결혼 생활은 1958년에 처음 시작된 자신의 외도로 인하여 나중엔 이봉조와 노전숙이 따로 홀로 살게되었다고 한다. 이후 이봉조는 1987년 8월 31일 심장마비로 사망하였다. 학력 별칭 재즈 테너 색소폰 연주자로서 두각을 나타내면서 한국의 스탠 게츠라는 별칭을 얻었다.',\n",
       " 'question': '이봉조의 스승이었던 테너 색소포니스트는 누구였을까?',\n",
       " 'id': 'korquad-29-009949',\n",
       " 'answers': {'answer_start': [255], 'text': ['엄토미']},\n",
       " 'document_id': 14283,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "whole_list[random.randint(1,len(whole_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dev_list = []\n",
    "train_dict = {}\n",
    "answer_dict = {}\n",
    "c = 0\n",
    "for j in range(0,5):\n",
    "    file_j = ('0'+str(j))[-2:]\n",
    "    with open('/opt/ml/input/data/KorQuAD_2.1/dev/korquad2.1_dev_{}.json'.format(file_j),'r') as f:\n",
    "        train_data = json.load(f)\n",
    "        for i in range(len(train_data['data'])):\n",
    "            answers = train_data['data'][i]['qas'][0]\n",
    "            answer_dict['answer_start'] = [len(preprocess_context(train_data['data'][i]['context'][:answers['answer']['answer_start']]).lstrip())]\n",
    "            answer_dict['text'] = [preprocess_context(answers['answer']['text']).strip()]\n",
    "            count_id = ('000000' + str(c))[-6:]\n",
    "            train_dict['title']=train_data['data'][i]['title']\n",
    "            train_dict['context']= preprocess_context(train_data['data'][i]['context']).strip()\n",
    "            train_dict['question']=answers['question']\n",
    "            train_dict['id']='korquad-{}-{}'.format(file_j,count_id)\n",
    "            train_dict['answers']=answer_dict\n",
    "            train_dict['document_id']=int(answers['id'])\n",
    "            train_dict['__index_level_0__']=0\n",
    "            if len(answer_dict['text'][0])>0:\n",
    "                if (len(train_dict['context']) <= 2000)&(len(answer_dict['text']) <= 80):\n",
    "                    if len(train_dict['context']) > answer_dict['answer_start'][0]:\n",
    "                        if train_dict['context'][answer_dict['answer_start'][0]] != answer_dict['text'][0][0]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            dev_list.append(train_dict)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            answer_dict={}\n",
    "            train_dict={}\n",
    "            c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '공법',\n",
       " 'context': '구별실익 강력한 중앙집권적 전제국가가 존재하던 로마시대, 근대에는 공사법 구별이 엄격하였다. 반면에 개인주의가 발달한 시대에는 사법의 영역이 확장되었다. 최근 복지국가사상이 발달하면서 공사법 구별이 엄격해지고 있다. 즉, 사적자치가 발달하면 공사법이 부정되고, 국가의 권력이 강력해지면 공사법의 구별이 엄격해진다. 이를 통해서, 공법을 사법에서 굳이 분리하려는 이유는, 국가와 개인이 소송할 때는, 개인과 개인이 소송할 때보다 국가에게 더 유리하게 판결을 하기 위해 공법이 사법에서 분리된다는 것을 알 수 있다. 영미법은 1천년이 넘도록 공사법 구별이 없이 사법으로만 규율하였는데, 20세기에 들어서 공법이 등장하고 있다는 것은, 영미법에서 개인주의나 사적자치가 후퇴하고 국가주의가 강화되고 있다는 의미로도 해석될 수 있다. 공법과 사법의 구별은 구체적 법률관계에 적용할 법규나 법원칙을 결정하기 위해, 또한 분쟁해결을 위한 쟁송수단의 선택과 결정을 위해서 필요하다. 공법과 사법의 관계 최근에 새로이 정립되는 사회법(노동법 및 경제관계법)은 사법과 공법이 융합된 것으로 사법의 공법화 경향을 보여준다. 공법·사법의 이원적 체계를 인정하지 않고 보통법의 지배 원리에 의한 일원적 체계의 영미법계에서는 20세기에 들어오면서 행정법의 성립과 함께 공법과 사법의 구별 문제가 대두되기 시작하였다. 구별 부정설 구별 부정론은 공법 관계도 그 본질에서는 사법 관계와 같은 법률관계인 점에서 차이가 없으며, 노동법·사회법·경제법 등과 같이 공법과 사법의 어느 하나에만 속하지 않는 새로운 법 현상이 출현하는 것을 이유로 공법과 사법의 구별을 부정하는 견해이다. 구별 긍정설 구별 긍정론 가운데 실체법상의 구별 필요성은 우리의 현행 법질서는 공법 관계인가 사법 관계인가에 따라 적용될 법규나 법원칙을 달리하므로 구체적 법률관계에 적용할 법규나 법원칙을 결정하기 위하여 공법과 사법의 구별은 필요하다. 예컨대 행정 주체와 사인(私人)간에 계약을 체결할 경우 공법상 계약이냐 사법상 계약이냐에 따라서 적용 법규나 법원칙이 달라지는 경우가 있다. 이처럼 절차법상의 구별 필요성은 구체적인 법적 분쟁이 있을 경우 이의 해결을 위한 쟁송 수단의 결정을 위하여 공법과 사법의 구별은 필요하다. 공법관계 공법 관계(公法關係)는 사법 관계(私法關係)와는 대응하는 개념으로 국가와 국가와의 관계·공공 단체 상호간의 관계·국가와 개인과의 관계 등 권력 관계·통치 관계 및 공익에 관한 사항을 규정하는 공법상의 법률관계를 말한다. 그러나 사법 관계와는 달리 당사자의 자치가 인정되지 않고 당사자가 대등한 지위에 있지 않으며 법률관계의 변동이 법에 구속된다. 공법 관계에서는 행정 주체가 상대방의 의사에 관계없이 일방적으로 획일·평등하게 규율하는 경우가 많으며, 사법 관계의 원칙이 그대로 적용되지 않는다. 국고관계등이 있다. 구별기준 구체적 분쟁이 발생했을 때, 그 사건이 행정사건인지 민사사건인지, 항고소송, 당사자소송의 행정소송인지 민사소송인지는 일반국민은 물론이고 법률전문가도 정확히 판단하기가 어렵다.[1] 판례는 ｢산업집적활성화 및 공장설립에 관한 법률｣상의 입주계약의 해지는 행정처분으로 보지만, 국유재산법상 일반재산인 국유림에 대한 대부료의 납입고지는 사법상의 이행청구로 본다.',\n",
       " 'question': '공법과 사법을 구별하려는 이유는 무엇인가?',\n",
       " 'id': 'korquad-00-000000',\n",
       " 'answers': {'answer_start': [5],\n",
       "  'text': ['강력한 중앙집권적 전제국가가 존재하던 로마시대, 근대에는 공사법 구별이 엄격하였다. 반면에 개인주의가 발달한 시대에는 사법의 영역이 확장되었다. 최근 복지국가사상이 발달하면서 공사법 구별이 엄격해지고 있다. 즉, 사적자치가 발달하면 공사법이 부정되고, 국가의 권력이 강력해지면 공사법의 구별이 엄격해진다. 이를 통해서, 공법을 사법에서 굳이 분리하려는 이유는, 국가와 개인이 소송할 때는, 개인과 개인이 소송할 때보다 국가에게 더 유리하게 판결을 하기 위해 공법이 사법에서 분리된다는 것을 알 수 있다. 영미법은 1천년이 넘도록 공사법 구별이 없이 사법으로만 규율하였는데, 20세기에 들어서 공법이 등장하고 있다는 것은, 영미법에서 개인주의나 사적자치가 후퇴하고 국가주의가 강화되고 있다는 의미로도 해석될 수 있다.']},\n",
       " 'document_id': 70543,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 510\n",
      "510 1020\n",
      "1020 1530\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(range(0,1530,510)):\n",
    "    with open('/opt/ml/input/data/KorQuAD_2.1/dev/preprocessed/valid_under2000_{}.json'.format(idx),'w') as outfile:\n",
    "        json.dump(dev_list[i:i+510],outfile)\n",
    "        print(i,i+510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5f30fd53ca4be2a5\n",
      "Found cached dataset json (/opt/ml/.cache/huggingface/datasets/json/default-5f30fd53ca4be2a5/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_json('/opt/ml/input/data/KorQuAD_2.1/train/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-56fe0ff52f29f51d\n",
      "Found cached dataset json (/opt/ml/.cache/huggingface/datasets/json/default-56fe0ff52f29f51d/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "dv = Dataset.from_json('/opt/ml/input/data/KorQuAD_2.1/dev/valid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['context'][0][ds['answers'][0]['answer_start'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['answers'][0]['text'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk('/opt/ml/input/data/train_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 3952\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "    num_rows: 42448\n",
       "})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_datasets([train_dataset['train'],ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 38496\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers', 'document_id', '__index_level_0__'],\n",
       "        num_rows: 4736\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetDict({'train' : ds, 'validation' : dv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
